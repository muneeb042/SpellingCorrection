{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoe1YI1JQmK3GravW4obYu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muneeb042/SpellingCorrection/blob/main/SpellingCorrection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vGrJq4TSnEd",
        "outputId": "5f99ca52-42e4-46a7-ddce-52a5c4ee72c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_file(input_file, output_file):\n",
        "    with open(input_file, 'r') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Split the text into words\n",
        "    tokens = text.split()\n",
        "\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write('\\n'.join(tokens))\n",
        "\n",
        "# Replace 'input.txt' and 'output.txt' with your file names\n",
        "tokenize_file('/content/drive/MyDrive/Colab Notebooks/Spell Correction/DWSample1-TXT.txt', '/content/drive/MyDrive/Colab Notebooks/Spell Correction/tokenized_output.txt')\n"
      ],
      "metadata": {
        "id": "q9xzIpHFTzyL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRSUTn9eWF8I",
        "outputId": "12cdbeef-06ea-40a7-8dd1-bbb8a47de7cd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.0-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "def correct_spelling(tokenized_file, output_file):\n",
        "    with open(tokenized_file, 'r') as file:\n",
        "        tokens = file.read().splitlines()\n",
        "\n",
        "    # Initialize SpellChecker\n",
        "    spell = SpellChecker()\n",
        "\n",
        "    # Correct spelling for each token\n",
        "    corrected_tokens = [spell.correction(token) or token for token in tokens]\n",
        "\n",
        "    # Write tokens and corrected words to the output file\n",
        "    with open(output_file, 'w') as file:\n",
        "        for token, corrected_token in zip(tokens, corrected_tokens):\n",
        "           #file.write(f\"{token}\\t\\t\\t{corrected_token}\\n\")\n",
        "            file.write(f\"{token.ljust(20)}{corrected_token}\\n\")\n",
        "\n",
        "\n",
        "# Replace 'tokenized_input.txt' and 'output_corrected.txt' with your file names\n",
        "correct_spelling('/content/drive/MyDrive/Colab Notebooks/Spell Correction/tokenized_output.txt', '/content/drive/MyDrive/Colab Notebooks/Spell Correction/output_corrected.txt')\n"
      ],
      "metadata": {
        "id": "lHTov5cpV8F8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "def correct_spelling_in_sentences(tokenized_file, output_file):\n",
        "    with open(tokenized_file, 'r') as file:\n",
        "        tokens = file.read().split()\n",
        "\n",
        "    # Initialize SpellChecker\n",
        "    spell = SpellChecker()\n",
        "\n",
        "    # Correct spelling for the entire content\n",
        "    corrected_tokens = [spell.correction(token) or token for token in tokens]\n",
        "    corrected_text = ' '.join(corrected_tokens)\n",
        "\n",
        "    # Write corrected text to the output file\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write(corrected_text)\n",
        "\n",
        "# Replace 'tokenized_input.txt' and 'output_corrected.txt' with your file names\n",
        "correct_spelling_in_sentences('/content/drive/MyDrive/Colab Notebooks/Spell Correction/tokenized_output.txt', '/content/drive/MyDrive/Colab Notebooks/Spell Correction/file_corrected.txt')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iw19JtSgXn_S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the contents of the output file\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/Spell Correction/output_corrected.txt', 'r') as file:\n",
        "    corrected_content = file.read()\n",
        "    print(corrected_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpLLWoLyZ6sI",
        "outputId": "a6244a2f-b838-4cf6-8ddf-7597d5e98e4b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilitatis          Utilitatis\n",
            "causa               cause\n",
            "amicitia            militia\n",
            "est                 best\n",
            "quaesita.           quaesita.\n",
            "Lorem               lore\n",
            "ipsum               issue\n",
            "dolor               dolor\n",
            "sit                 sit\n",
            "amet,               met\n",
            "consectetur         consectetur\n",
            "adipiscing          adipiscing\n",
            "elit.               elite\n",
            "Collatio            collation\n",
            "igitur              igniter\n",
            "ista                vista\n",
            "te                  the\n",
            "nihil               nihil\n",
            "iuvat.              iuvat.\n",
            "Honesta             honest\n",
            "oratio,             oration\n",
            "Socratica,          Socratica,\n",
            "Platonis            platonic\n",
            "etiam.              etiam.\n",
            "Primum              primus\n",
            "in                  in\n",
            "nostrane            rostrate\n",
            "potestate           potentate\n",
            "est,                best\n",
            "quid                quid\n",
            "meminerimus?        meminerimus?\n",
            "Duo                 Duo\n",
            "Reges:              recess\n",
            "constructio         construction\n",
            "interrete.          interpreted\n",
            "Quid,               quid\n",
            "si                  si\n",
            "etiam               team\n",
            "iucunda             iucunda\n",
            "memoria             memorial\n",
            "est                 best\n",
            "praeteritorum       praeteritorum\n",
            "malorum?            malorum?\n",
            "Si                  Si\n",
            "quidem,             quidem,\n",
            "inquit,             inquiry\n",
            "tollerem,           tollerem,\n",
            "sed                 see\n",
            "relinquo.           relinquo.\n",
            "An                  An\n",
            "nisi                nisi\n",
            "populari            popular\n",
            "fama?               mama\n",
            "Quamquam            Quamquam\n",
            "id                  id\n",
            "quidem              quite\n",
            "licebit             licit\n",
            "iis                 is\n",
            "existimare,         existimare,\n",
            "qui                 quit\n",
            "legerint.           legerint.\n",
            "Summum              summer\n",
            "a                   a\n",
            "vobis               obis\n",
            "bonum               bonus\n",
            "voluptas            volutes\n",
            "dicitur.            dicitur.\n",
            "At                  At\n",
            "hoc                 how\n",
            "in                  in\n",
            "eo                  to\n",
            "M.                  my\n",
            "Refert              refer\n",
            "tamen,              taken\n",
            "quo                 duo\n",
            "modo.               moon\n",
            "Quid                Quid\n",
            "sequatur,           sequatur,\n",
            "quid                quid\n",
            "repugnet,           repugned\n",
            "vident.             evident\n",
            "Iam                 am\n",
            "id                  id\n",
            "ipsum               issue\n",
            "absurdum,           absurdum,\n",
            "maximum             maximum\n",
            "malum               alum\n",
            "neglegi.            neglegi.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}